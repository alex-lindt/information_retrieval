{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Indexing and Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LsiModel, LdaModel, CoherenceModel, TfidfModel\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "\n",
    "from gensim.matutils import kullback_leibler\n",
    "from gensim import similarities\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import pytrec\n",
    "\n",
    "import os \n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import read_ap\n",
    "import download_ap\n",
    "from utils import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up directories to store models, corpora and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"LSI_LDA\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        os.makedirs(os.path.join(save_dir, \"models\"))\n",
    "        os.makedirs(os.path.join(save_dir, \"corpora\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ... (Skip if you don't want to load anything)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load you saved models here. Set the path below and run the cells you want to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default path (feel free to change)\n",
    "path_dictionary = save_dir + '/corpora/dictionary.dict'\n",
    "path_corpus_bow = save_dir + '/corpora/corpus_bow.mm'\n",
    "path_corpus_tfidf = save_dir + '/corpora/corpus_tfidf.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load(path_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bow_mm = MmCorpus(path_corpus_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_mm = MmCorpus(path_corpus_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load you saved models here. Set the path below and run the cells you want to load. <br>\n",
    "*Note that for the LSI tf-idf you also need to load the corresponding tf-idf model. This is needed during evaluation time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default path (feel free to change)\n",
    "path_lsi_bow = save_dir + '/models/LSI_BOW_model.mm'\n",
    "path_lsi_tfidf = save_dir + '/models/LSI_tfidf_model.mm'\n",
    "path_lda_bow = save_dir + '/models/LDA_bow_model.mm'\n",
    "path_tfidf_model = save_dir + '/models/tfidf_model.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSI_BOW_model = LsiModel.load(path_lsi_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSI_TFIDF_model = LsiModel.load(path_lsi_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_BOW_model = LdaModel.load(path_lda_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfModel.load(path_tfidf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data (Run this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data \n",
    "download_ap.download_dataset()\n",
    "docs_by_id = read_ap.get_processed_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct dictionary (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(docs_by_id.values())\n",
    "\n",
    "dictionary.filter_extremes(no_below=25, no_above=0.5)\n",
    "\n",
    "# save dictionary to disk \n",
    "dictionary.save(save_dir + '/corpora/dictionary.dict')  \n",
    "\n",
    "print('#Unique tokens in corpus: %i' % len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct corpora (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LSI BoW and LDA BoW only run the first cell. For LSI tf-idf run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct BOW corpus\n",
    "corpus_bow = [dictionary.doc2bow(doc) for doc in docs_by_id.values()]\n",
    "\n",
    "# serialize corpus to disk to prevent memory problems if corpus gets too large\n",
    "MmCorpus.serialize(save_dir + '/corpora/corpus_bow.mm', corpus_bow)  \n",
    "corpus_bow_mm = MmCorpus(save_dir + '/corpora/corpus_bow.mm')\n",
    "    \n",
    "print('#Documents in BOW corpus: %i' % len(corpus_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct tfidf corpus\n",
    "tfidf_model = TfidfModel(corpus_bow_mm)\n",
    "corpus_tfidf = tfidf_model[corpus_bow_mm]\n",
    "\n",
    "# serialize corpus to disk to prevent memory problems if corpus gets too large\n",
    "MmCorpus.serialize(save_dir + '/corpora/corpus_tfidf.mm', corpus_tfidf)  \n",
    "corpus_tfidf_mm = MmCorpus(save_dir + '/corpora/corpus_tfidf.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.save(save_dir + '/models/tfidf_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of topics you want to train on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params \n",
    "num_topics = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI BoW (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "LSI_BOW_model = LsiModel(corpus_bow_mm, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "toc = time.perf_counter() \n",
    "print(f\"Trained LSI BOW in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSI_BOW_model.save(save_dir + '/models/LSI_BOW_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI tf-idf (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "LSI_tfidf_model = LsiModel(corpus_tfidf_mm, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "toc = time.perf_counter() \n",
    "print(f\"Trained LSI tf-idf in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSI_tfidf_model.save(save_dir + '/models/LSI_tfidf_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA BoW (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "LDA_BOW_model = LdaModel(corpus=corpus_tfidf_mm,id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "toc = time.perf_counter() \n",
    "print(f\"Trained LDA BoW in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_BOW_model.save(save_dir + '/models/LDA_bow_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run the cells that apply to the model(s) you are evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI BoW\n",
    "LSI_BOW_model.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI tf-idf\n",
    "LSI_tfidf_model.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA BoW\n",
    "LDA_BOW_model.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(model, corpus, doc_ids, tfidf):\n",
    "    corpus_modelspace = model[corpus]\n",
    "    index = similarities.MatrixSimilarity(corpus_modelspace, dtype=float)  # ~3min\n",
    "    metrics = evaluate_queries(model, doc_ids, dictionary, corpus_modelspace, tfidf, index)\n",
    "\n",
    "    map_all = np.average([m['map'] for m in metrics.values()])\n",
    "    ndcg_all = np.average([m['ndcg'] for m in metrics.values()])\n",
    "\n",
    "    map_val = np.average([m['map'] for did, m in metrics.items() if int(did) in range(76, 101)])\n",
    "    ndcg_val = np.average([m['ndcg'] for did, m in metrics.items() if int(did) in range(76, 101)])\n",
    "\n",
    "    print((map_all, ndcg_all), (map_val, ndcg_val))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_queries(model, doc_ids, dictionary, corpus_modelspace, tfidf, index, save_path='LSI_LDA'):\n",
    "    qrels, queries = read_ap.read_qrels()\n",
    "\n",
    "    overall_result = {}\n",
    "\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        results = rank_docs(query, model, doc_ids, dictionary, corpus_modelspace, tfidf_model=tfidf, index=index)\n",
    "        overall_result[query_id] = dict(results)\n",
    "\n",
    "        if int(query_id) not in np.arange(76, 101):\n",
    "            evaluate.write_trec_results(query_id, results, save_path)\n",
    "\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'map', 'ndcg'})\n",
    "    metrics = evaluator.evaluate(overall_result)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_docs(query, model, doc_ids, dictionary, corpus_modelspace, tfidf_model=None, index=None):\n",
    "    query_prepro = read_ap.process_text(query)\n",
    "\n",
    "    # transform query to bow vector space\n",
    "    q_cspace = dictionary.doc2bow(query_prepro)\n",
    "\n",
    "    if not tfidf_model == None:\n",
    "        # transform query to tfidf vector space\n",
    "        q_cspace = tfidf_model[q_cspace]\n",
    "\n",
    "    q_modelspace = model[q_cspace]\n",
    "    \n",
    "    if isinstance(model, LsiModel):\n",
    "        ## LSI\n",
    "        scores = index[q_modelspace]\n",
    "\n",
    "        results = defaultdict(float)\n",
    "        for doc_id, score in zip(doc_ids, scores):\n",
    "          results[doc_id] = score\n",
    "\n",
    "        results = list(results.items())\n",
    "        results.sort(key=lambda _: -_[1])\n",
    "\n",
    "    elif isinstance(model, LdaModel):\n",
    "        ## LDA\n",
    "        doc_ids = list(doc_ids)\n",
    "        scores = []\n",
    "        # have to use the for loop, otherwise kullback_leibler has problems\n",
    "        for d in corpus_modelspace:\n",
    "            scores.append(float(-kullback_leibler(q_modelspace, d)))\n",
    "\n",
    "        # have to use torch here to do this more efficiently\n",
    "        order = torch.Tensor(scores).argsort(descending=True).numpy()\n",
    "        ordered_results = [(doc_ids[i], scores[i]) for i in order]\n",
    "        results = dict(ordered_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below evaluate the models using MAP and nDCG as a metric. Only run the cells that apply to the models you want to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI BoW\n",
    "run_evaluation(LSI_BOW_model, corpus_bow_mm, docs_by_id, tfidf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI tf-idf\n",
    "run_evaluation(LSI_tfidf_model, corpus_tfidf_mm, docs_by_id, tfidf=tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA BoW\n",
    "run_evaluation(LDA_BOW_model, corpus_bow_mm, docs_by_id, tfidf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSI(corpus, name, num_topics=500):\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    LSI_model = LsiModel(corpus, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Trained LSI {name} in {toc - tic:0.4f} seconds\")  # ~4min\n",
    "\n",
    "    LSI_model.save(f'/LSI_{name}_model_{num_topics}.mm')\n",
    "\n",
    "    return LSI_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_lsi(corpus, tfidf, name):\n",
    "\n",
    "    assert name in ['bow', 'tfidf']\n",
    "\n",
    "    for num_topics in [10, 50, 100, 500, 1000, 2000]:\n",
    "\n",
    "        print(\"--training\")\n",
    "        lsi_model = train_LSI(corpus, name, num_topics=num_topics)\n",
    "\n",
    "        print(\"--evaluating\")\n",
    "        # Run this if you want to evaluate LSI tfidf model\n",
    "        lsi_metrics = run_evaluation(model=lsi_model,\n",
    "                                     corpus=corpus,\n",
    "                                     doc_ids=docs_by_id.keys(),\n",
    "                                     tfidf=tfidf)\n",
    "\n",
    "        with open(f'LSI_{name}_{num_topics}', \"w\") as writer:\n",
    "            json.dump(lsi_metrics, writer, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cells perform the grid search on the number of topics for LSI BoW and LSI Tf-idf. Only run the cells that apply to the models you want to perform the grid search on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search LSI BoW\n",
    "grid_search_lsi(corpus_bow_mm, tfidf=None, name=\"bow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search LSI TF-IDF\n",
    "grid_search_lsi(corpus_tfidf_mm, tfidf=tfidf_model, name=\"tfidf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
