{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Indexing and Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/vanes/Miniconda3/envs/ir1-hw2/Lib/site-packages')\n",
    "\n",
    "from gensim.models import LsiModel, LdaModel, CoherenceModel, TfidfModel\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "\n",
    "from gensim.matutils import kullback_leibler\n",
    "from gensim import similarities\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# import pytrec\n",
    "\n",
    "import os \n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import read_ap\n",
    "import download_ap\n",
    "# from utils import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up directories to store models, corpora and dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"LSI_LDA\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        os.makedirs(os.path.join(save_dir, \"models\"))\n",
    "        os.makedirs(os.path.join(save_dir, \"corpora\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ... (Skip if you don't want to load anything)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load you saved models here. Set the path below and run the cells you want to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default path (feel free to change)\n",
    "path_dictionary = save_dir + '/corpora/dictionary.dict'\n",
    "path_corpus_bow = save_dir + '/corpora/corpus_bow.mm'\n",
    "path_corpus_tfidf = save_dir + '/corpora/corpus_tfidf.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load(path_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bow_mm = MmCorpus(path_corpus_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_mm = MmCorpus(path_corpus_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load you saved models here. Set the path below and run the cells you want to load. <br>\n",
    "*Note that for the LSI tf-idf you also need to load the corresponding tf-idf model. This is needed during evaluation time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default path (feel free to change)\n",
    "path_lsi_bow = save_dir + '/models/LSI_BOW_model.mm'\n",
    "path_lsi_tfidf = save_dir + '/models/LSI_tfidf_model.mm'\n",
    "path_lda_bow = save_dir + '/models/LDA_bow_model.mm'\n",
    "path_tfidf_model = save_dir + '/models/tfidf_model.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_bow_model = LsiModel.load(path_lsi_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_tfidf_model = LsiModel.load(path_lsi_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow_model = LdaModel.load(path_lda_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfModel.load(path_tfidf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data (Run this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed data \n",
    "download_ap.download_dataset()\n",
    "docs_by_id = read_ap.get_processed_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset (REMOVE THIS BEFORE HANDING IN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_by_id = dict(list(docs_by_id.items())[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct dictionary (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(docs_by_id.values())\n",
    "\n",
    "dictionary.filter_extremes(no_below=25, no_above=0.5)\n",
    "\n",
    "# save dictionary to disk \n",
    "dictionary.save(save_dir + '/corpora/dictionary.dict')  \n",
    "\n",
    "print('#Unique tokens in corpus: %i' % len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct corpora (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For LSI BoW and LDA BoW only run the first cell. For LSI tf-idf run all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct BOW corpus\n",
    "corpus_bow = [dictionary.doc2bow(doc) for doc in docs_by_id.values()]\n",
    "\n",
    "# serialize corpus to disk to prevent memory problems if corpus gets too large\n",
    "MmCorpus.serialize(save_dir + '/corpora/corpus_bow.mm', corpus_bow)  \n",
    "corpus_bow_mm = MmCorpus(save_dir + '/corpora/corpus_bow.mm')\n",
    "    \n",
    "print('#Documents in BOW corpus: %i' % len(corpus_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct tfidf corpus\n",
    "tfidf_model = TfidfModel(corpus_bow_mm)\n",
    "corpus_tfidf = tfidf_model[corpus_bow_mm]\n",
    "\n",
    "# serialize corpus to disk to prevent memory problems if corpus gets too large\n",
    "MmCorpus.serialize(save_dir + '/corpora/corpus_tfidf.mm', corpus_tfidf)  \n",
    "corpus_tfidf_mm = MmCorpus(save_dir + '/corpora/corpus_tfidf.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.save(save_dir + '/models/tfidf_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of topics you want to train on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params \n",
    "num_topics = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI BoW (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained LSI BOW in 7.2385 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "LSI_BOW_model = LsiModel(corpus_bow_mm, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "toc = time.perf_counter() \n",
    "print(f\"Trained LSI BOW in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSI_BOW_model.save(save_dir + '/models/LSI_BOW_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI tf-idf (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained LSI tf-idf in 7.4356 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "LSI_tfidf_model = LsiModel(corpus_tfidf_mm, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "toc = time.perf_counter() \n",
    "print(f\"Trained LSI tf-idf in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSI_tfidf_model.save(save_dir + '/models/LSI_tfidf_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA BoW (Skip if already loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained LDA tf-idf in 33.4586 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.perf_counter()\n",
    "\n",
    "LDA_BOW_model = LdaModel(corpus=corpus_tfidf_mm,id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "toc = time.perf_counter() \n",
    "print(f\"Trained LDA BoW in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_BOW_model.save(save_dir + '/models/LDA_bow_model.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show topics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run the cells that apply to the model(s) you are evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.513*\"percent\" + -0.224*\"12\" + -0.186*\"state\" + -0.146*\"new\" + -0.136*\"report\" + -0.112*\"10\" + -0.102*\"presid\" + -0.101*\"n\\'t\" + -0.100*\"bush\" + -0.100*\"say\" + -0.097*\"one\" + -0.096*\"democrat\" + -0.093*\"nation\" + -0.092*\"last\" + -0.091*\"million\" + -0.090*\"also\" + -0.090*\"govern\" + -0.088*\"peopl\" + -0.088*\"u.s.\" + -0.086*\"two\"'),\n",
       " (1,\n",
       "  '0.642*\"percent\" + 0.414*\"12\" + -0.135*\"state\" + 0.108*\"10\" + -0.102*\"new\" + -0.089*\"say\" + -0.086*\"one\" + -0.086*\"govern\" + -0.085*\"n\\'t\" + -0.084*\"presid\" + -0.083*\"u.s.\" + -0.080*\"peopl\" + -0.078*\"two\" + -0.076*\"offici\" + -0.075*\"also\" + 0.074*\"precinct\" + -0.072*\"nation\" + -0.066*\"last\" + -0.066*\"million\" + -0.063*\"unit\"'),\n",
       " (2,\n",
       "  '0.896*\"10\" + -0.177*\"12\" + -0.168*\"percent\" + 0.107*\"stake\" + 0.105*\"total\" + 0.103*\"26\" + 0.098*\"dukaki\" + 0.093*\"gephardt\" + 0.089*\"jackson\" + 0.088*\"gore\" + 0.084*\"precinct\" + 0.078*\"simon\" + 0.067*\"report\" + 0.067*\"hart\" + 0.067*\"babbitt\" + 0.062*\"uncommit\" + 0.054*\"bush\" + 0.047*\"dole\" + 0.041*\"democrat\" + 0.038*\"deleg\"'),\n",
       " (3,\n",
       "  '0.280*\"democrat\" + 0.259*\"bush\" + -0.242*\"10\" + 0.202*\"campaign\" + 0.202*\"dole\" + 0.188*\"ye\" + 0.184*\"republican\" + 0.172*\"deleg\" + 0.161*\"primari\" + 0.160*\"dukaki\" + 0.158*\"vote\" + 0.156*\"state\" + 0.127*\"tuesday\" + 0.119*\"candid\" + -0.118*\"report\" + 0.117*\"jackson\" + 0.117*\"robertson\" + 0.113*\"gephardt\" + -0.111*\"12\" + 0.104*\"gore\"'),\n",
       " (4,\n",
       "  '-0.937*\"ye\" + -0.146*\"republican\" + -0.127*\"democrat\" + 0.089*\"bush\" + 0.073*\"dole\" + 0.067*\"campaign\" + 0.061*\"state\" + 0.051*\"dukaki\" + -0.045*\"million\" + 0.043*\"primari\" + 0.042*\"robertson\" + 0.042*\"deleg\" + -0.041*\"price\" + -0.041*\"billion\" + -0.040*\"10\" + 0.040*\"tuesday\" + 0.038*\"south\" + -0.038*\"cent\" + 0.037*\"jackson\" + 0.034*\"n\\'t\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSI BoW\n",
    "LSI_BOW_model.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.138*\"percent\" + 0.108*\"bush\" + 0.092*\"democrat\" + 0.086*\"dole\" + 0.086*\"dukaki\" + 0.085*\"state\" + 0.083*\"campaign\" + 0.079*\"stock\" + 0.077*\"vote\" + 0.075*\"million\" + 0.072*\"deleg\" + 0.072*\"soviet\" + 0.072*\"jackson\" + 0.071*\"govern\" + 0.071*\"polic\" + 0.069*\"presid\" + 0.068*\"compani\" + 0.067*\"u.s.\" + 0.067*\"primari\" + 0.067*\"gephardt\"'),\n",
       " (1,\n",
       "  '-0.288*\"bush\" + -0.235*\"dole\" + -0.226*\"dukaki\" + -0.187*\"deleg\" + -0.182*\"democrat\" + -0.172*\"jackson\" + -0.168*\"gore\" + -0.164*\"gephardt\" + -0.164*\"primari\" + -0.157*\"campaign\" + -0.156*\"robertson\" + 0.154*\"stock\" + -0.126*\"republican\" + -0.126*\"vote\" + -0.115*\"simon\" + -0.112*\"candid\" + -0.109*\"percent\" + -0.106*\"super\" + -0.099*\"illinoi\" + 0.098*\"market\"'),\n",
       " (2,\n",
       "  '-0.314*\"stock\" + -0.196*\"percent\" + -0.192*\"index\" + -0.187*\"market\" + -0.155*\"trade\" + -0.141*\"price\" + -0.140*\"cent\" + -0.129*\"share\" + -0.126*\"rose\" + -0.121*\"exchang\" + -0.113*\"averag\" + -0.107*\"dow\" + 0.105*\"polic\" + -0.096*\"billion\" + -0.089*\"jone\" + -0.089*\"point\" + -0.089*\"analyst\" + -0.088*\"yen\" + -0.085*\"dollar\" + -0.084*\"volum\"'),\n",
       " (3,\n",
       "  '0.201*\"soviet\" + 0.184*\"noriega\" + 0.176*\"panama\" + 0.164*\"shultz\" + 0.146*\"israel\" + -0.130*\"court\" + 0.130*\"troop\" + 0.123*\"sandinista\" + 0.123*\"palestinian\" + 0.122*\"hondura\" + 0.118*\"arab\" + 0.113*\"contra\" + 0.110*\"isra\" + 0.109*\"shamir\" + 0.102*\"militari\" + 0.102*\"peac\" + 0.097*\"nicaragua\" + 0.096*\"missil\" + 0.095*\"delval\" + -0.094*\"polic\"'),\n",
       " (4,\n",
       "  '-0.435*\"cent\" + 0.394*\"noriega\" + 0.355*\"panama\" + 0.203*\"delval\" + -0.155*\"bushel\" + 0.144*\"panamanian\" + -0.141*\"soybean\" + 0.125*\"stock\" + -0.116*\"lower\" + -0.114*\"soviet\" + -0.106*\"israel\" + -0.100*\"higher\" + -0.098*\"wheat\" + -0.096*\"palestinian\" + -0.093*\"arab\" + -0.088*\"isra\" + -0.083*\"futur\" + 0.083*\"drug\" + -0.078*\"price\" + 0.076*\"canal\"')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSI tf-idf\n",
    "LSI_tfidf_model.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(174,\n",
       "  '0.000*\"imbal\" + 0.000*\"mute\" + 0.000*\"lent\" + 0.000*\"exchange-list\" + 0.000*\"outnumb\" + 0.000*\"nyse\" + 0.000*\"humphrey\" + 0.000*\"10.5\" + 0.000*\"kan.\" + 0.000*\"toyota\" + 0.000*\"usa\" + 0.000*\"0.1\" + 0.000*\"0.2\" + 0.000*\"0.3\" + 0.000*\"0.4\" + 0.000*\"0.8\" + 0.000*\"1.4\" + 0.000*\"dynam\" + 0.000*\"2.2\" + 0.000*\"volum\"'),\n",
       " (329,\n",
       "  '0.000*\"imbal\" + 0.000*\"mute\" + 0.000*\"lent\" + 0.000*\"exchange-list\" + 0.000*\"outnumb\" + 0.000*\"nyse\" + 0.000*\"humphrey\" + 0.000*\"10.5\" + 0.000*\"kan.\" + 0.000*\"toyota\" + 0.000*\"usa\" + 0.000*\"0.1\" + 0.000*\"0.2\" + 0.000*\"0.3\" + 0.000*\"0.4\" + 0.000*\"0.8\" + 0.000*\"1.4\" + 0.000*\"dynam\" + 0.000*\"2.2\" + 0.000*\"volum\"'),\n",
       " (444,\n",
       "  '0.000*\"imbal\" + 0.000*\"mute\" + 0.000*\"lent\" + 0.000*\"exchange-list\" + 0.000*\"outnumb\" + 0.000*\"nyse\" + 0.000*\"humphrey\" + 0.000*\"10.5\" + 0.000*\"kan.\" + 0.000*\"toyota\" + 0.000*\"usa\" + 0.000*\"0.1\" + 0.000*\"0.2\" + 0.000*\"0.3\" + 0.000*\"0.4\" + 0.000*\"0.8\" + 0.000*\"1.4\" + 0.000*\"dynam\" + 0.000*\"2.2\" + 0.000*\"volum\"'),\n",
       " (152,\n",
       "  '0.000*\"imbal\" + 0.000*\"mute\" + 0.000*\"lent\" + 0.000*\"exchange-list\" + 0.000*\"outnumb\" + 0.000*\"nyse\" + 0.000*\"humphrey\" + 0.000*\"10.5\" + 0.000*\"kan.\" + 0.000*\"toyota\" + 0.000*\"usa\" + 0.000*\"0.1\" + 0.000*\"0.2\" + 0.000*\"0.3\" + 0.000*\"0.4\" + 0.000*\"0.8\" + 0.000*\"1.4\" + 0.000*\"dynam\" + 0.000*\"2.2\" + 0.000*\"volum\"'),\n",
       " (418,\n",
       "  '0.000*\"imbal\" + 0.000*\"mute\" + 0.000*\"lent\" + 0.000*\"exchange-list\" + 0.000*\"outnumb\" + 0.000*\"nyse\" + 0.000*\"humphrey\" + 0.000*\"10.5\" + 0.000*\"kan.\" + 0.000*\"toyota\" + 0.000*\"usa\" + 0.000*\"0.1\" + 0.000*\"0.2\" + 0.000*\"0.3\" + 0.000*\"0.4\" + 0.000*\"0.8\" + 0.000*\"1.4\" + 0.000*\"dynam\" + 0.000*\"2.2\" + 0.000*\"volum\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA BoW\n",
    "LDA_BOW_model.print_topics(num_topics=5, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(model, corpus, doc_ids, tfidf):\n",
    "    corpus_modelspace = model[corpus]\n",
    "    index = similarities.MatrixSimilarity(corpus_modelspace, dtype=float)  # ~3min\n",
    "    metrics = evaluate_queries(model, doc_ids, dictionary, corpus_modelspace, tfidf, index)\n",
    "\n",
    "    map_all = np.average([m['map'] for m in metrics.values()])\n",
    "    ndcg_all = np.average([m['ndcg'] for m in metrics.values()])\n",
    "\n",
    "    map_val = np.average([m['map'] for did, m in metrics.items() if int(did) in range(76, 101)])\n",
    "    ndcg_val = np.average([m['ndcg'] for did, m in metrics.items() if int(did) in range(76, 101)])\n",
    "\n",
    "    print((map_all, ndcg_all), (map_val, ndcg_val))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_queries(model, doc_ids, dictionary, corpus_modelspace, tfidf, index, save_path='LSI'):\n",
    "    qrels, queries = read_ap.read_qrels()\n",
    "\n",
    "    overall_result = {}\n",
    "\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        results = rank_docs(query, model, doc_ids, dictionary, corpus_modelspace, tfidf_model=tfidf, index=index)\n",
    "        overall_result[query_id] = dict(results)\n",
    "\n",
    "        if int(query_id) not in np.arange(76, 101):\n",
    "            evaluate.write_trec_results(query_id, results, save_path)\n",
    "\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {'map', 'ndcg'})\n",
    "    metrics = evaluator.evaluate(overall_result)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_docs(query, model, doc_ids, dictionary, corpus_modelspace, tfidf_model=None, index=None):\n",
    "    query_prepro = read_ap.process_text(query)\n",
    "\n",
    "    # transform query to bow vector space\n",
    "    q_cspace = dictionary.doc2bow(query_prepro)\n",
    "\n",
    "    if not tfidf_model == None:\n",
    "        # transform query to tfidf vector space\n",
    "        q_cspace = tfidf_model[q_cspace]\n",
    "\n",
    "    q_modelspace = model[q_cspace]\n",
    "    \n",
    "    if isinstance(model, LsiModel):\n",
    "        ## LSI\n",
    "        scores = index[q_modelspace]\n",
    "\n",
    "        results = defaultdict(float)\n",
    "        for doc_id, score in zip(doc_ids, scores):\n",
    "          results[doc_id] = score\n",
    "\n",
    "        results = list(results.items())\n",
    "        results.sort(key=lambda _: -_[1])\n",
    "\n",
    "    elif isinstance(model, LdaModel):\n",
    "        ## LDA\n",
    "        doc_ids = list(doc_ids)\n",
    "        scores = []\n",
    "        # have to use the for loop, otherwise kullback_leibler has problems\n",
    "        for d in corpus_modelspace:\n",
    "            scores.append(float(-kullback_leibler(q_modelspace, d)))\n",
    "\n",
    "        # have to use torch here to do this more efficiently\n",
    "        order = torch.Tensor(scores).argsort(descending=True).numpy()\n",
    "        ordered_results = [(doc_ids[i], scores[i]) for i in order]\n",
    "        results = dict(ordered_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below evaluate the models using MAP and nDCG as a metric. Only run the cells that apply to the models you want to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI BoW\n",
    "run_evaluation(LSI_BOW_model, corpus_bow_mm, docs_by_id, tfidf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI tf-idf\n",
    "run_evaluation(LSI_tfidf_model, corpus_tfidf_mm, docs_by_id, tfidf=tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA BoW\n",
    "run_evaluation(LDA_BOW_model, corpus_bow_mm, docs_by_id, tfidf=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSI(corpus, name, num_topics=500):\n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    LSI_model = LsiModel(corpus, id2word=dictionary, num_topics=num_topics)\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Trained LSI {name} in {toc - tic:0.4f} seconds\")  # ~4min\n",
    "\n",
    "    LSI_model.save(f'/LSI_{name}_model_{num_topics}.mm')\n",
    "\n",
    "    return LSI_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_lsi(corpus, tfidf, name):\n",
    "\n",
    "    assert name in ['bow', 'tfidf']\n",
    "\n",
    "    for num_topics in [10, 50, 100, 500, 1000, 2000]:\n",
    "\n",
    "        print(\"--training\")\n",
    "        lsi_model = train_LSI(corpus, name, num_topics=num_topics)\n",
    "\n",
    "        print(\"--evaluating\")\n",
    "        # Run this if you want to evaluate LSI tfidf model\n",
    "        lsi_metrics = run_evaluation(model=lsi_model,\n",
    "                                     corpus=corpus,\n",
    "                                     doc_ids=docs_by_id.keys(),\n",
    "                                     tfidf=tfidf)\n",
    "\n",
    "        with open(f'LSI_{name}_{num_topics}', \"w\") as writer:\n",
    "            json.dump(lsi_metrics, writer, indent=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
