{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 501\n",
      "Split: train\n",
      "\tNumber of queries 19943\n",
      "\tNumber of docs 473092\n",
      "Split: validation\n",
      "\tNumber of queries 2993\n",
      "\tNumber of docs 71041\n",
      "Split: test\n",
      "\tNumber of queries 6734\n",
      "\tNumber of docs 163439\n"
     ]
    }
   ],
   "source": [
    "data = dataset.get_dataset().get_data_folds()[0]\n",
    "data.read_data()\n",
    "\n",
    "\n",
    "print(f\"Number of features: {data.num_features}\")\n",
    "# print some statistics\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    print(f\"Split: {split}\")\n",
    "    split = getattr(data, split)\n",
    "    print(f\"\\tNumber of queries {split.num_queries()}\")\n",
    "    print(f\"\\tNumber of docs {split.num_docs()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QID 6167 has 19 documents\n",
      "QID 1922 has 64 documents\n",
      "QID 17539 has 36 documents\n",
      "QID 5683 has 19 documents\n",
      "QID 788 has 22 documents\n",
      "QID 2682 has 22 documents\n",
      "QID 7489 has 8 documents\n",
      "QID 2704 has 52 documents\n",
      "QID 5470 has 32 documents\n",
      "QID 8804 has 7 documents\n"
     ]
    }
   ],
   "source": [
    "# queries go from 0 to num_queries\n",
    "queries = np.arange(0, data.train.num_queries())\n",
    "# loop over 10 random queries\n",
    "for qid in np.random.choice(queries, size=10):\n",
    "    # as the name suggests, query_feat gives \n",
    "    qd_features = data.train.query_feat(qid)\n",
    "    labels = data.train.query_labels(qid)\n",
    "    print(\"QID {} has {} documents\".format(qid, qd_features.shape[0]))\n",
    "    # number of labels == number of documents\n",
    "    assert qd_features.shape[0] == labels.shape[0]\n",
    "    \n",
    "    # doc_feat, as the name suggests, gives you features for one doc and query\n",
    "    doc_ids = np.arange(qd_features.shape[0])\n",
    "    qd_features_2 = np.zeros_like(qd_features)\n",
    "    for did in doc_ids:\n",
    "        qd_features_2[did] = data.train.doc_feat(qid, did)\n",
    "    # this is the same as the output returned by query_feat\n",
    "    assert np.all(qd_features == qd_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example function to extract the features / labels for an set of indices\n",
    "# the indicies go from 0 to feature.matrix.shape[0] (exclusive)\n",
    "def get_batch(split, idx):\n",
    "    return split.feature_matrix[idx, :], split.label_vector[idx]\n",
    "\n",
    "# get a random batch of indices from 0 to feature_matrix.shape[0] (exclusive)\n",
    "batch_idx = np.random.permutation(np.arange(data.train.feature_matrix.shape[0]))[:10]\n",
    "X, y = get_batch(data.train, batch_idx)\n",
    "assert X.shape[0] == y.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
